export { default as theme } from './theme';
import { Notes } from 'mdx-deck';

# Blameless Retros:

## From Errors and Outcomes ‚Üí System Design

### By Alessia Bellisario

---

# ‚ò†Ô∏è Postmortem ‚ò†Ô∏è

- Not all created equal
- What makes the good ones good (and reproduceable)? ü§î
- "Blameless Retro"... sounds nice üòá

<Notes>
  <ul>
    <li>
      By a show of hands, who has participated in a postmortem before? Positive
      postmortem experiences? Negative ones?
    </li>
    <li>
      We had a minor "miss" -- I was talking to Christophe about what happened,
      and thought we should try a blameless retro
    </li>
    <li>I've been a part of a few of them, some better than others</li>
    <li>Sounded nice!</li>
  </ul>
</Notes>

---

## Goals

1. Learn about blameless retros
2. Model one

## Agenda

- "Just Culture"
- First stories vs. Second stories
- Hindsight Bias and Fundamental Attribution Error

---

## "Just Culture"

- Philosophy borrowed from the world of healthcare
- In October 1999, Dr. Lucian Leape briefed US Congress on the state of human error management in the medical industry

<Notes>
  <ul>
    <li>
      "Just culture" is a philosophy of organizational theory in medical field
    </li>
  </ul>
</Notes>

---

### Problem

- 1MM+ people injured by errors in treatment at hospitals each year in the US
- 120,000 deaths arising from those errors at a cost of 33B
- 3x greater than those who die in automobile accidents
- 1000x greater than those who die in commercial aircraft accidents
- Only 2 to 3% of major errors reported through hospital incident reporting systems
- Health care workers often report only what they cannot conceal

---

## Just Culture, cont'd

- Dr. Leape testified that the single greatest impediment to error prevention is that

> **‚Äú...we punish people for making mistakes.‚Äù** ([source](http://www.chpso.org/sites/main/files/file-attachments/marx_primer.pdf))

- "The just culture is a **learning culture** that is constantly improving and oriented toward patient safety." ([source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3776518/))
- Requires a change in focus from errors and outcomes ‚Üí system design

<Notes>
  <ul>
    <li>
      Engineering leadership borrowed this idea of a "Just Culture" and shaped
      it for a tech context
    </li>
    <li>Deterrence!!</li>
  </ul>
</Notes>

---

## First stories vs. Second stories

# Situations, not people, cause errors

<Notes>
  <ul>
    <li>Written by a bunch of PhD researchers in system safety, human error</li>
  </ul>
</Notes>

---

## First stories vs. Second stories cont'd

| First stories                                                                  | Second stories                                                                                                         |
| ------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------- |
| Human error is the **cause** of failure                                        | Human error is the **effect** of systemic vulnerabilities deeper inside the organization                               |
| Saying what people should have done is a satisfying way to describe failure... | But doesn‚Äôt explain why it made sense for them to do what they did                                                     |
| Telling people to be more careful will make the problem go away                | Only by constantly seeking out its vulnerabilities can organizations enhance safety (or reliability, resilience, etc.) |

From the book [Behind Human Error](https://www.amazon.com/Behind-Human-Error-David-Woods/dp/0754678342)

---

## "Accidents waiting to happen"

- `some-command restore --flag # deletes production dbüòµ`
- two different vials of medicine with near-identical labels

---

## Hindsight Bias and Fundamental Attribution Error

- **[Hindsight Bias](https://en.wikipedia.org/wiki/Hindsight_bias)**: the common tendency for people to perceive events that have already occurred as having been more predictable than they actually were before the events took place
- **[Fundamental Attribution Error](https://en.wikipedia.org/wiki/Fundamental_attribution_error)**: people tend to unduly emphasize internal characteristics (character or intention), rather than external factors, in explaining other people's behavior, but not our own

---

## Blameless Retros

- Seek out Second stories ("the story behind the story," or vulnerabilities in the system)
- Understand **how** something happened, not "why"
  - the answer to "why" is often a cause-and-effect chain that gets created after the fact by virtue of hindsight
  - [Look for descriptions, not explanations](https://github.com/etsy/DebriefingFacilitationGuide/blob/master/guide/05-the-art-of-asking-questions.md#remember-to-look-for-descriptions-not-explanations)

---

## Conclusion

- Encourage people who do make mistakes to be the experts on educating the rest of the organization how not to make them in the future
- Success = at least one person learns one thing that will affect how they work in the future

---

## Resources

- [Blameless Postmortems from the Etsy Blog](https://codeascraft.com/2012/05/22/blameless-postmortems/)
- [Debrief Facilitation Guide](https://github.com/etsy/DebriefingFacilitationGuide/blob/master/guide/05-the-art-of-asking-questions.md#remember-to-look-for-descriptions-not-explanations)

---

# The end!
